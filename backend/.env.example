# ============================================
# DraftApply LLM Configuration
# ============================================
# Primary provider (fallback chain tries others if this fails)

# Provider: ollama | lmstudio | localai | groq | gemini | mistral | together | openai
LLM_PROVIDER=ollama

# Fallback: tries other configured providers if primary fails
# Set to 'false' to disable fallback (use only primary provider)
USE_FALLBACK=true

# Fallback order: Primary → Ollama → Groq → Gemini → Mistral → Together → OpenAI
# (only providers with API keys configured will be used)

# ============================================
# LOCAL PROVIDERS (No API key needed!)
# ============================================

# --- Ollama (default) ---
# Install: brew install ollama && ollama pull llama3.2 && ollama serve
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# --- LM Studio ---
# Download from https://lmstudio.ai, load a model, start local server
# LMSTUDIO_URL=http://localhost:1234/v1
# LMSTUDIO_MODEL=local-model

# --- LocalAI ---
# Run: docker run -p 8080:8080 localai/localai
# LOCALAI_URL=http://localhost:8080/v1
# LOCALAI_MODEL=gpt-3.5-turbo

# ============================================
# CLOUD PROVIDERS (Free tiers available)
# ============================================

# --- Groq (Recommended - very fast, generous free tier) ---
# Get free key: https://console.groq.com
# GROQ_API_KEY=gsk_your_key_here
# GROQ_MODEL=llama-3.3-70b-versatile

# --- Google Gemini (15 requests/min free) ---
# Get free key: https://aistudio.google.com/apikey
# GEMINI_API_KEY=your_key_here
# GEMINI_MODEL=gemini-1.5-flash

# --- Mistral ---
# Get key: https://console.mistral.ai
# MISTRAL_API_KEY=your_key_here
# MISTRAL_MODEL=mistral-small-latest

# --- Together AI ($5 free credit) ---
# Get key: https://together.ai
# TOGETHER_API_KEY=your_key_here
# TOGETHER_MODEL=meta-llama/Llama-3.3-70B-Instruct-Turbo

# --- OpenAI (paid) ---
# OPENAI_API_KEY=sk-your_key_here
# OPENAI_MODEL=gpt-4o

# ============================================
# Server Configuration
# ============================================
PORT=3001
NODE_ENV=development
